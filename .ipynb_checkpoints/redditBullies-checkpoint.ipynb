{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Algorithm that uses NLP and ML to determine if a comment made on social media (specifically reddit)\n",
    "#Data was gathered from Kaggle's Reddit May 2015 hosted data off of a sql server\n",
    "#Required packages: jupyter notebook, numpy, pandas, sklearn\n",
    "#If no jupyter, run redditBullies.py in terminal.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "controversiality = pd.read_csv('controversiality.csv', error_bad_lines = False)\n",
    "noncontroversiality = pd.read_csv('non-controversiality.csv', error_bad_lines = False)\n",
    "#combine the controversial and noncontroversial data\n",
    "data = pd.concat((controversiality, noncontroversiality), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99998 entries, 0 to 99999\n",
      "Data columns (total 2 columns):\n",
      "author    99998 non-null int64\n",
      "body      99998 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "simple = pd.concat([data['controversiality'], data['body']], axis=1, keys=['author', 'body'])\n",
    "#drop the null data\n",
    "simple[pd.isnull(simple).any(axis=1)]\n",
    "simple = simple.drop(simple.index[[7572,97008]])\n",
    "simple.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author                                               body\n",
      "0       1  Because we arent responsible for the actions o...\n",
      "1       1  I honestly wouldnt have believed it if I didnt...\n",
      "2       1  There is also many intelligence service player...\n",
      "3       1  The implications of that varies between cultur...\n",
      "4       1  I am a bot whose sole purpose is to improve th...\n",
      "5       1  Youre just trying to get to the front page  I ...\n",
      "6       1  For those about to lynch this guy herehttpnere...\n",
      "7       1  True though you can find papers about early ch...\n",
      "8       1  Yes After days of dealing with car accidents a...\n",
      "9       1  Icefrog went fucking mad I have literally no i...\n"
     ]
    }
   ],
   "source": [
    "#eliminate non-alpha characters\n",
    "simple['body'].replace(regex=True,inplace=True,to_replace=r'([^\\s\\w]|_)+',value=r'')\n",
    "simple['body'].replace(regex=True,inplace=True,to_replace=r'/s|\\n',value=r'')\n",
    "print(simple.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create test and training set\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(simple.body, \n",
    "                                                                                                 simple.author, \n",
    "                                                                                                 test_size=0.2, \n",
    "                                                                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create vectorizer for feature selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df = 0.1,\n",
    "                               stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform the reddit comments into tuples of words and their frequency of occurence\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use only the top 100 features\n",
    "features_train = features_train[:100].toarray()\n",
    "labels_train   = labels_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Differente machine learning models used\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5338\n"
     ]
    }
   ],
   "source": [
    "#Run model, get accuracy\n",
    "clf = DecisionTreeClassifier()\n",
    "# clf = LogisticRegression()\n",
    "# clf = RandomForestClassifier()\n",
    "# clf = xgb.fit(features_train, labels_train)\n",
    "# clf = XGBClassifier(max_depth=6,\n",
    "#                     learning_rate=0.1,\n",
    "#                     )\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Accuracy:\", accuracy_score(labels_test, pred)) #Beat random guessing!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking: \n",
      "1 feature no.65095 (0.0783410138248849) people\n",
      "2 feature no.6157 (0.04249097066873295) allowed\n",
      "3 feature no.59520 (0.04016269830332278) nfl\n",
      "4 feature no.76674 (0.03987802017358663) say\n",
      "5 feature no.74624 (0.039231378826040254) rmensrights\n",
      "6 feature no.72031 (0.03802068772714565) reddit\n",
      "7 feature no.95182 (0.03772247964042327) wallets\n",
      "8 feature no.36622 (0.037305244678516467) good\n",
      "9 feature no.13052 (0.03629898984267144) booooooo\n",
      "10 feature no.12095 (0.03604558706599522) bit\n"
     ]
    }
   ],
   "source": [
    "#rank most important words that determine if a comment is controversial or not\n",
    "importances = clf.feature_importances_\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print('Feature Ranking: ')\n",
    "for i in range(10):\n",
    "    print(\"{} feature no.{} ({}) {}\".format(i+1,indices[i],\n",
    "                                            importances[indices[i]], \n",
    "                                            vectorizer.get_feature_names()[indices[i]]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
